{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2271054,"sourceType":"datasetVersion","datasetId":76785}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torch torchvision tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:40.196125Z","iopub.execute_input":"2025-01-13T06:48:40.196540Z","iopub.status.idle":"2025-01-13T06:48:43.509612Z","shell.execute_reply.started":"2025-01-13T06:48:40.196511Z","shell.execute_reply":"2025-01-13T06:48:43.508695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms, models \nfrom torchvision.utils import make_grid\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom PIL import Image\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:43.516490Z","iopub.execute_input":"2025-01-13T06:48:43.516732Z","iopub.status.idle":"2025-01-13T06:48:47.448533Z","shell.execute_reply.started":"2025-01-13T06:48:43.516712Z","shell.execute_reply":"2025-01-13T06:48:47.447846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:47.449212Z","iopub.execute_input":"2025-01-13T06:48:47.449597Z","iopub.status.idle":"2025-01-13T06:48:47.453854Z","shell.execute_reply.started":"2025-01-13T06:48:47.449575Z","shell.execute_reply":"2025-01-13T06:48:47.452957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nwith open('/kaggle/input/pytorch-challange-flower-dataset/cat_to_name.json', 'r') as f:\n    cat2name_mapping = json.load(f)\n#print(cat2name_mapping)\nclass_names = [cat2name_mapping[cat] for cat in cat2name_mapping]\ncat_list = [cat for cat in cat2name_mapping]\n#print(cat_list)\nprint(class_names)\nN=list(range(len(class_names)))\ncat2N_mapping=dict(zip(cat_list,N)) \nname2N_mapping=dict(zip(class_names,N)) \nN2name_mapping=dict(zip(N,class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:47.454763Z","iopub.execute_input":"2025-01-13T06:48:47.455100Z","iopub.status.idle":"2025-01-13T06:48:47.474188Z","shell.execute_reply.started":"2025-01-13T06:48:47.455066Z","shell.execute_reply":"2025-01-13T06:48:47.473517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path_label=[]\nfor dirname, _, filenames in os.walk('/kaggle/input/pytorch-challange-flower-dataset/dataset/train'):\n    for filename in filenames:\n        if filename[-4:]=='.jpg' and dirname.split('/')[-1] in cat_list:\n            path=os.path.join(dirname, filename)\n            label=dirname.split('/')[-1]\n            path_label+=[(path,cat2N_mapping[label])]\n            \ntpath_label=[]\nfor dirname, _, filenames in os.walk('/kaggle/input/pytorch-challange-flower-dataset/dataset/valid'):\n    for filename in filenames:\n        if filename[-4:]=='.jpg' and dirname.split('/')[-1] in cat_list:\n            path=os.path.join(dirname, filename)\n            label=dirname.split('/')[-1]\n            tpath_label+=[(path,cat2N_mapping[label])]  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:47.475027Z","iopub.execute_input":"2025-01-13T06:48:47.475283Z","iopub.status.idle":"2025-01-13T06:48:50.005590Z","shell.execute_reply.started":"2025-01-13T06:48:47.475263Z","shell.execute_reply":"2025-01-13T06:48:50.004866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, path_label, transform=None):\n        self.path_label = path_label\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.path_label)\n\n    def __getitem__(self, idx):\n        path, label = self.path_label[idx]\n        img = Image.open(path).convert('RGB')\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.006366Z","iopub.execute_input":"2025-01-13T06:48:50.006635Z","iopub.status.idle":"2025-01-13T06:48:50.011375Z","shell.execute_reply.started":"2025-01-13T06:48:50.006602Z","shell.execute_reply":"2025-01-13T06:48:50.010682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = ImageDataset(path_label, transform)\ntest_data = ImageDataset(tpath_label, transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.014238Z","iopub.execute_input":"2025-01-13T06:48:50.014471Z","iopub.status.idle":"2025-01-13T06:48:50.032956Z","shell.execute_reply.started":"2025-01-13T06:48:50.014453Z","shell.execute_reply":"2025-01-13T06:48:50.032067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = [label for _, label in train_data.path_label]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.034450Z","iopub.execute_input":"2025-01-13T06:48:50.034699Z","iopub.status.idle":"2025-01-13T06:48:50.047483Z","shell.execute_reply.started":"2025-01-13T06:48:50.034680Z","shell.execute_reply":"2025-01-13T06:48:50.046867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader=DataLoader(train_data,batch_size=32,shuffle=True)\ntest_loader=DataLoader(test_data,batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.048246Z","iopub.execute_input":"2025-01-13T06:48:50.048498Z","iopub.status.idle":"2025-01-13T06:48:50.061176Z","shell.execute_reply.started":"2025-01-13T06:48:50.048479Z","shell.execute_reply":"2025-01-13T06:48:50.060405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in train_loader:\n    break\nim=make_grid(images,nrow=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.061940Z","iopub.execute_input":"2025-01-13T06:48:50.062184Z","iopub.status.idle":"2025-01-13T06:48:50.287967Z","shell.execute_reply.started":"2025-01-13T06:48:50.062144Z","shell.execute_reply":"2025-01-13T06:48:50.287235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\nplt.imshow(np.transpose(im.numpy(),(1,2,0)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.288671Z","iopub.execute_input":"2025-01-13T06:48:50.288900Z","iopub.status.idle":"2025-01-13T06:48:50.933120Z","shell.execute_reply.started":"2025-01-13T06:48:50.288881Z","shell.execute_reply":"2025-01-13T06:48:50.932277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inv_normalize=transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],\n                                    std=[1/0.229,1/0.224,1/0.225])\nim=inv_normalize(im)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.934029Z","iopub.execute_input":"2025-01-13T06:48:50.934342Z","iopub.status.idle":"2025-01-13T06:48:50.953948Z","shell.execute_reply.started":"2025-01-13T06:48:50.934315Z","shell.execute_reply":"2025-01-13T06:48:50.953249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\nplt.imshow(np.transpose(im.numpy(),(1,2,0)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:50.954612Z","iopub.execute_input":"2025-01-13T06:48:50.954834Z","iopub.status.idle":"2025-01-13T06:48:51.517053Z","shell.execute_reply.started":"2025-01-13T06:48:50.954814Z","shell.execute_reply":"2025-01-13T06:48:51.516130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models_sota = {\n    \"ResNet50\": models.resnet50(pretrained=True),\n    \"EfficientNet_B0\": models.efficientnet_b0(pretrained=True),\n    \"DenseNet121\": models.densenet121(pretrained=True),\n    \"ViT_B_16\": models.vit_b_16(pretrained=True),\n    \"Swin_T\": models.swin_t(pretrained=True),\n    \"ConvNeXt_T\": models.convnext_tiny(pretrained=True),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:51.517921Z","iopub.execute_input":"2025-01-13T06:48:51.518195Z","iopub.status.idle":"2025-01-13T06:48:54.599126Z","shell.execute_reply.started":"2025-01-13T06:48:51.518149Z","shell.execute_reply":"2025-01-13T06:48:54.598396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:54.599990Z","iopub.execute_input":"2025-01-13T06:48:54.600329Z","iopub.status.idle":"2025-01-13T06:48:54.658404Z","shell.execute_reply.started":"2025-01-13T06:48:54.600291Z","shell.execute_reply":"2025-01-13T06:48:54.657444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom tqdm import tqdm\n\ndef train_and_evaluate(model_name, model, train_loader, test_loader, num_classes=102, epochs=5, lr=1e-3):\n    print(f\"\\nTraining {model_name}...\")\n\n    # Đưa mô hình về thiết bị (GPU nếu có)\n    model = model.to(device)\n    \n    # Sử dụng DataParallel nếu có nhiều GPU\n    if torch.cuda.device_count() > 1:\n        model = nn.DataParallel(model)\n\n    # Thay đổi output layer để phù hợp với số lớp của bạn\n    if hasattr(model, 'fc'):  # Ví dụ với ResNet\n        model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n    elif hasattr(model, 'classifier'):  # Ví dụ với DenseNet, EfficientNet\n        model.classifier = nn.Linear(model.classifier.in_features, num_classes).to(device)\n    elif hasattr(model, 'heads'):  # Ví dụ với ViT\n        model.heads.head = nn.Linear(model.heads.head.in_features, num_classes).to(device)\n    \n    # Đảm bảo criterion sử dụng device\n    criterion = nn.CrossEntropyLoss().to(device)\n    \n    # Tạo optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss, correct = 0, 0\n        # Sử dụng tqdm để tạo thanh tiến độ\n        with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch') as pbar:\n            for images, labels in train_loader:\n                # Di chuyển dữ liệu vào device\n                images, labels = images.to(device), labels.to(device)\n                \n                # Zero gradients, backward pass, optimizer step\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n                # Cập nhật thống kê\n                train_loss += loss.item()\n                correct += (outputs.argmax(1) == labels).sum().item()\n\n                # Cập nhật thanh tiến độ\n                pbar.set_postfix(loss=train_loss / (pbar.n + 1), accuracy=correct / len(train_loader.dataset))\n                pbar.update(1)  # Cập nhật thanh tiến độ\n\n        # Tính toán độ chính xác và in ra\n        accuracy = correct / len(train_loader.dataset)\n        print(f\"Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f}, Accuracy: {accuracy:.4f}\")\n\n    # Đánh giá trên tập test\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            # Di chuyển dữ liệu vào device\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            correct += (outputs.argmax(1) == labels).sum().item()\n\n    # Tính độ chính xác trên test set\n    test_accuracy = correct / len(test_loader.dataset)\n    print(f\"Test Accuracy for {model_name}: {test_accuracy:.4f}\")\n\n    # Lưu checkpoint\n    checkpoint_path = f\"{model_name}_checkpoint.pth\"  # Tên checkpoint theo model\n    checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'epoch': epochs,\n        'loss': train_loss / len(train_loader),\n        'accuracy': accuracy,\n    }\n    torch.save(checkpoint, checkpoint_path)\n    print(f\"Checkpoint saved to {checkpoint_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:54.659303Z","iopub.execute_input":"2025-01-13T06:48:54.659602Z","iopub.status.idle":"2025-01-13T06:48:54.675769Z","shell.execute_reply.started":"2025-01-13T06:48:54.659580Z","shell.execute_reply":"2025-01-13T06:48:54.674974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for model_name, model in models_sota.items():\n    train_and_evaluate(model_name, model, train_loader, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T06:48:54.676517Z","iopub.execute_input":"2025-01-13T06:48:54.676760Z","iopub.status.idle":"2025-01-13T07:42:53.994884Z","shell.execute_reply.started":"2025-01-13T06:48:54.676728Z","shell.execute_reply":"2025-01-13T07:42:53.993844Z"}},"outputs":[],"execution_count":null}]}